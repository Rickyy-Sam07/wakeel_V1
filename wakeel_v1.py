# -*- coding: utf-8 -*-
"""wakeel_V1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RYthxls4fFqUyt3oiJ24o0Sr6nrOkl2r
"""
!pip install transformers faiss-cpu datasets

from datasets import load_dataset
from transformers import GPT2Tokenizer, GPT2LMHeadModel

dataset = load_dataset("kshitij230/Indian-Law")

model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

import faiss
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

texts = [f"{example['Instruction']} {example['Response']}" for example in dataset['train']]

vectorizer = TfidfVectorizer()
tfidf_vectors = vectorizer.fit_transform(texts)
tfidf_vectors = tfidf_vectors.toarray()

dimension = tfidf_vectors.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(tfidf_vectors)

def retrieve_documents(query, top_k=5):
    query_vector = vectorizer.transform([query]).toarray()
    distances, indices = index.search(query_vector, top_k)
    retrieved_docs = [texts[idx] for idx in indices[0]]
    return retrieved_docs

def generate_response(query, retrieved_responses, max_new_tokens=700):
    context = "\n".join(retrieved_responses)
    input_text = f"Query: {query}\n\nContext:\n{context}"
    inputs = tokenizer(input_text, return_tensors="pt", max_length=200, truncation=True)
    outputs = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        early_stopping=True,
    )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response_lines = splitter(response, max_line_length=50)
    formatted_response = "\n".join(response_lines)
    return formatted_response

def splitter(text, max_line_length):
    words = text.split()
    lines = []
    current_line = ""

    for word in words:
        if len(current_line) + len(word) + 1 <= max_line_length:
            current_line += f" {word}" if current_line else word
        else:
            lines.append(current_line)
            current_line = word

    if current_line:
        lines.append(current_line)

    return lines

def rag_pipeline(query, top_k=5):
    retrieved_docs = retrieve_documents(query, top_k)
    response = generate_response(query, retrieved_docs)
    return response

!pip install groq

import os
from groq import Groq

client = Groq(api_key='your_key')

def rag_with_groq(query):
    rag_response = rag_pipeline(query)

    response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {
                "role": "system",
                "content": f"You are a highly knowledgeable legal assistant specializing in Indian law. Summarize and filter important points. If you don't find relevant points from the context, then use your own knowledge. Make sure to specify the laws and articles. The input context: {rag_response}. Don't answer anything outside the Indian law domain."
            },
            {
                "role": "user",
                "content": f"### Question: {query}\n\n### Relevant Context:\n{rag_response}\n\n### Answer:"
            }
        ],
        max_tokens=500,
        temperature=0.5
    )

    return response.choices[0].message.content

print("""
                      ___.   .__                         __
  ___________    _____\_ |__ |  |______________    _____/  |______
 /  ___/\__  \  /     \| __ \|  |  \_  __ \__  \  /    \   __\__  \
 \___ \  / __ \|  Y Y  \ \_\ \   Y  \  | \// __ \|   |  \  |  / __ \_
/____  >(____  /__|_|  /___  /___|  /__|  (____  /___|  /__| (____  /
     \/      \/      \/    \/     \/           \/     \/          \/ """)

key = ".god"
while True:
    query = input("Ok tell me what happened: ")
    if query.lower() == 'q':
        break

    if key in query:
        rag_response = rag_pipeline(query)
        print("RAG Response:", rag_response)
        response = rag_with_groq(query)
        print("Mr. Wakeel Sahab:\n", response)
    else:
        response = rag_with_groq(query)
        print("Mr. Wakeel Sahab:\n", response)
